{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl3ee8O76yqhwciwg5z22a"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python_operator  import PythonOperator\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "default_args = {\n",
        "    'owner': 'XYZ Telecoms',\n",
        "    'depends_on_past': False,\n",
        "    'start_date': datetime(2023, 3, 19),\n",
        "    'email_on_failure': False,\n",
        "    'email_on_retry': False,\n",
        "    'retries': 1,\n",
        "    'retry_delay': timedelta(minutes=5)\n",
        "}\n",
        "\n",
        "dag = DAG('data_pipeline', default_args=default_args, schedule_interval='@daily')\n",
        "\n",
        "def extract_data():\n",
        "    customer_df = pd.read_csv('customer_data.csv')\n",
        "    order_df = pd.read_csv('order_data.csv')\n",
        "    payment_df = pd.read_csv('payment_data.csv')\n",
        "    return customer_df, order_df, payment_df\n",
        "\n",
        "def transform_data():\n",
        "    customer_df, order_df, payment_df = extract_data()\n",
        "\n",
        "    # convert date fields to the correct format using pd.to_datetime\n",
        "    customer_df['date_of_birth'] = pd.to_datetime(customer_df['date_of_birth'])\n",
        "    order_df['order_date'] = pd.to_datetime(order_df['order_date'])\n",
        "    payment_df['payment_date'] = pd.to_datetime(payment_df['payment_date'])\n",
        "\n",
        "    # merge customer and order dataframes on the customer_id column\n",
        "    merged_df = pd.merge(customer_df, order_df, on='customer_id')\n",
        "\n",
        "    # merge payment dataframe with the merged dataframe on the order_id and customer_id columns\n",
        "    merged_df = pd.merge(merged_df, payment_df, on=['order_id', 'customer_id'])\n",
        "\n",
        "    # drop unnecessary columns like customer_id and order_id\n",
        "    merged_df.drop(['customer_id', 'order_id'], axis=1, inplace=True)\n",
        "\n",
        "    # group the data by customer and aggregate the amount paid using sum\n",
        "    agg_df = merged_df.groupby(['first_name', 'last_name', 'email', 'country', 'gender', 'date_of_birth']).agg({'amount': 'sum'})\n",
        "\n",
        "    # create a new column to calculate the total value of orders made by each customer\n",
        "    agg_df['total_order_value'] = merged_df.groupby(['first_name', 'last_name', 'email', 'country', 'gender', 'date_of_birth']).agg({'price': 'sum'})\n",
        "\n",
        "    # calculate the customer lifetime value using the formula CLV = (average order value) x (number of orders made per year) x (average customer lifespan)\n",
        "    today = datetime.today().date()\n",
        "    agg_df['customer_ltv'] = agg_df['total_order_value'] * (365 / (today - agg_df.index.get_level_values('date_of_birth').date).dt.days) * (agg_df['amount'] / agg_df.index.get_level_values('amount').nunique())\n",
        "\n",
        "    return agg_df.reset_index()\n",
        "\n",
        "def load_data():\n",
        "   # load the transformed data into Postgres database\n",
        "    transformed_data = transform_data()\n",
        "    engine = create_engine('postgresql+psycopg2://postgres:admin@localhost:5442/customer_lifecycle')\n",
        "    transformed_data.to_sql('customer_ltv', engine, if_exists='replace', index=False)\n",
        "\n",
        "with dag:\n",
        "    extract_data_task = PythonOperator(\n",
        "        task_id='extract_data',\n",
        "        python_callable=extract_data,\n",
        "        dag=dag\n",
        "    )\n",
        "\n",
        "    transform_data_task = PythonOperator(\n",
        "        task_id='transform_data',\n",
        "        python_callable=transform_data,\n",
        "        dag=dag\n",
        "    )\n",
        "\n",
        "    load_data_task = PythonOperator(\n",
        "        task_id='load_data',\n",
        "        python_callable=load_data,\n",
        "        dag=dag\n",
        "    )\n",
        "\n",
        "    extract_data_task >> transform_data_task >> load_data_task\n"
      ],
      "metadata": {
        "id": "nMqAaMtDLAyG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}